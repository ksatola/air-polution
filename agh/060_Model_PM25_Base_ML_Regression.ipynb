{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "From: https://github.com/ksatola\n",
    "Version: 0.0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - PM2.5 - Machine Learning Modelling - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Machine Learning Regression](#mlr)\n",
    "- Hourly prediction\n",
    "    - [Load hourly data](#data_h)\n",
    "    - [Base Modelling](#model_h)\n",
    "    - [Hyper-parameters Tuning](#model_h_tune)\n",
    "- Daily prediction\n",
    "    - [Load daily data](#data_d)\n",
    "    - [Modelling](#model_d)\n",
    "    - [Hyper-parameters Tuning](#model_d_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from model import (\n",
    "    #get_ensemble_models_for_regression,\n",
    "    #get_analytical_view_for_meta_model,\n",
    "    #fit_base_models,\n",
    "    #fit_meta_model,\n",
    "    #evaluate_models,\n",
    "    #predict_with_super_learner\n",
    "#)\n",
    "\n",
    "from model import (\n",
    "    get_pm25_data_for_modelling,\n",
    "    split_df_for_ml_modelling,\n",
    "    get_models_for_regression\n",
    ")\n",
    "\n",
    "from measure import (\n",
    "    #get_rmse\n",
    "    score_ml_models\n",
    ")\n",
    "\n",
    "#from plot import (\n",
    "    #plot_train_test_predicted,\n",
    "#    plot_observed_vs_predicted,\n",
    "#    plot_observations_to_predictions_relationship,\n",
    "    #fit_theoretical_dist_and_plot\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='mlr'></a>\n",
    "\n",
    "## Machine Learning Regression\n",
    "\n",
    "XXXXXXXXX\n",
    "\n",
    "- Linear Algorithms: Logistic Regression.\n",
    "- Nonlinear Algorithms: Classification and Regression Trees (CART), Support Vector Machines (SVM), Gaussian Naive Bayes (NB) and k-Nearest Neighbors (KNN).\n",
    "\n",
    "Napisac z scikit learn wstep do regresji\n",
    "\n",
    "wypisac funkcje - zob. ponizej\n",
    "\n",
    "Hyper based on CV and training data\n",
    "Final check based on test data - TODO\n",
    "\n",
    "w pracy opisac generalne podejscie do ML, proste, dla najlepszych hyper, i dla nich super learner\n",
    "\n",
    "XXXX\n",
    "<img src=\"images/super_learner_algorithm_flow_diagram.png\" style=\"width: 800px;\"/>\n",
    "From https://www.degruyter.com/view/journals/sagmb/6/1/article-sagmb.2007.6.1.1309.xml.xml\n",
    "\n",
    "\n",
    "score models na zbiorze testowym!\n",
    "zrobic final test wybranych modeli ML na zbiorze testowym i policzyc RMSE -> symulacja predykcji\n",
    "jesli linear regression jest najlepsze to sprawdzic OLS assumptions dla zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data_h'></a>\n",
    "\n",
    "## Load hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "common.py | 42 | get_pm25_data_for_modelling | 04-Jun-20 23:04:52 | INFO: Dataframe loaded: /Users/ksatola/Documents/git/air-polution/agh/data/dfpm25_2008-2018_ml_24hours_lags.hdf\n",
      "common.py | 43 | get_pm25_data_for_modelling | 04-Jun-20 23:04:52 | INFO: Dataframe size: (96378, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-10</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.246170</td>\n",
       "      <td>-13.443917</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>9.915600</td>\n",
       "      <td>10.136910</td>\n",
       "      <td>13.456166</td>\n",
       "      <td>14.163808</td>\n",
       "      <td>14.019144</td>\n",
       "      <td>20.936157</td>\n",
       "      <td>23.611710</td>\n",
       "      <td>28.537801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.839649</td>\n",
       "      <td>-18.246170</td>\n",
       "      <td>-13.443917</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>9.915600</td>\n",
       "      <td>10.136910</td>\n",
       "      <td>13.456166</td>\n",
       "      <td>14.163808</td>\n",
       "      <td>14.019144</td>\n",
       "      <td>20.936157</td>\n",
       "      <td>23.611710</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.761822</td>\n",
       "      <td>-25.839649</td>\n",
       "      <td>-18.246170</td>\n",
       "      <td>-13.443917</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>9.915600</td>\n",
       "      <td>10.136910</td>\n",
       "      <td>13.456166</td>\n",
       "      <td>14.163808</td>\n",
       "      <td>14.019144</td>\n",
       "      <td>20.936157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.697300</td>\n",
       "      <td>-16.761822</td>\n",
       "      <td>-25.839649</td>\n",
       "      <td>-18.246170</td>\n",
       "      <td>-13.443917</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>9.915600</td>\n",
       "      <td>10.136910</td>\n",
       "      <td>13.456166</td>\n",
       "      <td>14.163808</td>\n",
       "      <td>14.019144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.515568</td>\n",
       "      <td>-6.697300</td>\n",
       "      <td>-16.761822</td>\n",
       "      <td>-25.839649</td>\n",
       "      <td>-18.246170</td>\n",
       "      <td>-13.443917</td>\n",
       "      <td>0.156504</td>\n",
       "      <td>9.915600</td>\n",
       "      <td>10.136910</td>\n",
       "      <td>13.456166</td>\n",
       "      <td>14.163808</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t        t-1        t-2        t-3        t-4        t-5  \\\n",
       "0 -18.246170 -13.443917   0.156504   9.915600  10.136910  13.456166   \n",
       "1 -25.839649 -18.246170 -13.443917   0.156504   9.915600  10.136910   \n",
       "2 -16.761822 -25.839649 -18.246170 -13.443917   0.156504   9.915600   \n",
       "3  -6.697300 -16.761822 -25.839649 -18.246170 -13.443917   0.156504   \n",
       "4  -2.515568  -6.697300 -16.761822 -25.839649 -18.246170 -13.443917   \n",
       "\n",
       "         t-6        t-7        t-8        t-9       t-10  month  day  hour  \\\n",
       "0  14.163808  14.019144  20.936157  23.611710  28.537801      1    1    11   \n",
       "1  13.456166  14.163808  14.019144  20.936157  23.611710      1    1    12   \n",
       "2  10.136910  13.456166  14.163808  14.019144  20.936157      1    1    13   \n",
       "3   9.915600  10.136910  13.456166  14.163808  14.019144      1    1    14   \n",
       "4   0.156504   9.915600  10.136910  13.456166  14.163808      1    1    15   \n",
       "\n",
       "   dayofyear  weekofyear  dayofweek  quarter  season  \n",
       "0          1           1          1        1       1  \n",
       "1          1           1          1        1       1  \n",
       "2          1           1          1        1       1  \n",
       "3          1           1          1        1       1  \n",
       "4          1           1          1        1       1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfh = get_pm25_data_for_modelling('ml', 'h')\n",
    "dfh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 19)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit training data to 2 last years of hourly data (for performance reasons)\n",
    "df = dfh[-365*24:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-10</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87618</th>\n",
       "      <td>26.797137</td>\n",
       "      <td>-23.627303</td>\n",
       "      <td>-11.066157</td>\n",
       "      <td>-6.896479</td>\n",
       "      <td>-21.893212</td>\n",
       "      <td>-29.155953</td>\n",
       "      <td>-37.303764</td>\n",
       "      <td>-20.646928</td>\n",
       "      <td>-30.484597</td>\n",
       "      <td>-29.887483</td>\n",
       "      <td>-38.440042</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87619</th>\n",
       "      <td>21.497168</td>\n",
       "      <td>26.797137</td>\n",
       "      <td>-23.627303</td>\n",
       "      <td>-11.066157</td>\n",
       "      <td>-6.896479</td>\n",
       "      <td>-21.893212</td>\n",
       "      <td>-29.155953</td>\n",
       "      <td>-37.303764</td>\n",
       "      <td>-20.646928</td>\n",
       "      <td>-30.484597</td>\n",
       "      <td>-29.887483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87620</th>\n",
       "      <td>29.507759</td>\n",
       "      <td>21.497168</td>\n",
       "      <td>26.797137</td>\n",
       "      <td>-23.627303</td>\n",
       "      <td>-11.066157</td>\n",
       "      <td>-6.896479</td>\n",
       "      <td>-21.893212</td>\n",
       "      <td>-29.155953</td>\n",
       "      <td>-37.303764</td>\n",
       "      <td>-20.646928</td>\n",
       "      <td>-30.484597</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87621</th>\n",
       "      <td>16.637266</td>\n",
       "      <td>29.507759</td>\n",
       "      <td>21.497168</td>\n",
       "      <td>26.797137</td>\n",
       "      <td>-23.627303</td>\n",
       "      <td>-11.066157</td>\n",
       "      <td>-6.896479</td>\n",
       "      <td>-21.893212</td>\n",
       "      <td>-29.155953</td>\n",
       "      <td>-37.303764</td>\n",
       "      <td>-20.646928</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87622</th>\n",
       "      <td>17.504926</td>\n",
       "      <td>16.637266</td>\n",
       "      <td>29.507759</td>\n",
       "      <td>21.497168</td>\n",
       "      <td>26.797137</td>\n",
       "      <td>-23.627303</td>\n",
       "      <td>-11.066157</td>\n",
       "      <td>-6.896479</td>\n",
       "      <td>-21.893212</td>\n",
       "      <td>-29.155953</td>\n",
       "      <td>-37.303764</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               t        t-1        t-2        t-3        t-4        t-5  \\\n",
       "87618  26.797137 -23.627303 -11.066157  -6.896479 -21.893212 -29.155953   \n",
       "87619  21.497168  26.797137 -23.627303 -11.066157  -6.896479 -21.893212   \n",
       "87620  29.507759  21.497168  26.797137 -23.627303 -11.066157  -6.896479   \n",
       "87621  16.637266  29.507759  21.497168  26.797137 -23.627303 -11.066157   \n",
       "87622  17.504926  16.637266  29.507759  21.497168  26.797137 -23.627303   \n",
       "\n",
       "             t-6        t-7        t-8        t-9       t-10  month  day  \\\n",
       "87618 -37.303764 -20.646928 -30.484597 -29.887483 -38.440042      1    1   \n",
       "87619 -29.155953 -37.303764 -20.646928 -30.484597 -29.887483      1    1   \n",
       "87620 -21.893212 -29.155953 -37.303764 -20.646928 -30.484597      1    1   \n",
       "87621  -6.896479 -21.893212 -29.155953 -37.303764 -20.646928      1    1   \n",
       "87622 -11.066157  -6.896479 -21.893212 -29.155953 -37.303764      1    1   \n",
       "\n",
       "       hour  dayofyear  weekofyear  dayofweek  quarter  season  \n",
       "87618     1          1           1          0        1       1  \n",
       "87619     2          1           1          0        1       1  \n",
       "87620     3          1           1          0        1       1  \n",
       "87621     4          1           1          0        1       1  \n",
       "87622     5          1           1          0        1       1  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_h'></a>\n",
    "\n",
    "## Base Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_df_for_ml_modelling(data=df, \n",
    "                                                             target_col='t', \n",
    "                                                             train_size=0.02) # train_size=0.00024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8584, 18)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 18)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))\n",
      "('ElasticNet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False))\n",
      "('SVR', SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))\n",
      "('DecisionTreeRegressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best'))\n",
      "('KNeighborsRegressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform'))\n",
      "('AdaBoostRegressor', AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                 n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                 warm_start=False))\n",
      "('RandomForestRegressor', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False))\n",
      "('ExtraTreesRegressor', ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
      "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                    max_samples=None, min_impurity_decrease=0.0,\n",
      "                    min_impurity_split=None, min_samples_leaf=1,\n",
      "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                    n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                    random_state=None, verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "# Define regression models in scope\n",
    "reg_models = get_models_for_regression()\n",
    "models = []\n",
    "\n",
    "for model in reg_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 5.56711818313286, (std. dev. 0.1985876635301725)\n",
      "ElasticNet, RMSE 5.570228808723629, (std. dev. 0.18766919576955177)\n",
      "SVR, RMSE 7.182387115542616, (std. dev. 0.16268675420669534)\n",
      "DecisionTreeRegressor, RMSE 7.873690915369804, (std. dev. 0.27778285055964064)\n",
      "KNeighborsRegressor, RMSE 6.653434322953375, (std. dev. 0.3006601773427491)\n",
      "AdaBoostRegressor, RMSE 6.429824450932732, (std. dev. 0.10930505848320025)\n",
      "BaggingRegressor, RMSE 5.898093853859504, (std. dev. 0.25298260577679066)\n",
      "RandomForestRegressor, RMSE 5.8841056604815085, (std. dev. 0.21989443125211608)\n",
      "ExtraTreesRegressor, RMSE 5.909062322838997, (std. dev. 0.25022463868645484)\n",
      "CPU times: user 22.3 s, sys: 692 ms, total: 23 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Perform initial ranking\n",
    "scores, results, names = score_ml_models(X_train=X_train,\n",
    "                                         y_train=y_train,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\", \n",
    "                                         seed=123)\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression, RMSE 5.56711818313286, (std. dev. 0.1985876635301725)\n",
    "ElasticNet, RMSE 5.570228808723629, (std. dev. 0.18766919576955177)\n",
    "SVR, RMSE 7.182387115542616, (std. dev. 0.16268675420669534)\n",
    "DecisionTreeRegressor, RMSE 7.841333664708597, (std. dev. 0.17552023518416768)\n",
    "KNeighborsRegressor, RMSE 6.653434322953375, (std. dev. 0.3006601773427491)\n",
    "AdaBoostRegressor, RMSE 6.425082457443115, (std. dev. 0.18253907464994834)\n",
    "BaggingRegressor, RMSE 5.921852717688901, (std. dev. 0.20225920292760463)\n",
    "RandomForestRegressor, RMSE 5.939068350982593, (std. dev. 0.2842986689298549)\n",
    "ExtraTreesRegressor, RMSE 5.858054046678829, (std. dev. 0.2381438572224743)\n",
    "CPU times: user 21.1 s, sys: 926 ms, total: 22.1 s\n",
    "Wall time: 21.5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB0AAAILCAYAAACkWuQiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XmcJWddL/7PlwybhIQZIkuAEHZRBK5MWLwgCQSQuIDLhXBBQMUI/uBeEeGqqJmgIoIoimtUBJRdFgOEfd8hkSQkEBZDgCQgxBmWsBOe3x/1NHOmc3q27qd7uuf9fr361XXqVNXz1HKq6nzqqTrVWgsAAADASrvSWlcAAAAA2JiEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAYEOqqmdX1R8OmvaDq+r1u3n/2Kq6aETZG1VVHVVVl1XVIWtdFwBg5QgdAFjXquqtVbWjqq66WmW21p7XWrv3TB1aVd18tcrfnaq6Y1WdXlVfrKrtVfX+qvrFta7XnrTWPt1aO7S1dvla12VBVT28qi7vYciXq+rsqvrJmfeP7uv+g4vGO6KqvlVVF870u2tVvbuqvtTXy7uq6pg55cz+HblqMwsAgwgdAFi3quroJHdL0pL89CqVuWk1ytkfVXWXJG9O8rYkN09y7SSPSnLftazXnhzIyzTJe1prhya5VpK/SfLCqrrWomG+r6puM/P6fyf55MKLqjosyauSPDPJliQ3SHJKkm8uLmfR3yUD5gcAVpXQAYD17KFJ3pvk2UketrsBq+oJVfXZqrqkqh4x2zqhqg6vqudW1Req6lNV9btVdaX+3sP7Vek/r6r/TrKt93tnf//tvYiz+9XpB86U+biq+nwv9xdn+j+7qv6mql7Tx3lXVV2vqp7RW22cX1X/Y2b4/1dVF1fVV6rqo1V1zyVm82lJntNa+5PW2qVtcmZr7QEz0/qVqvpEv9p+2uzV9L5Mfq2qPt7L+oOqulm/Qv/lqnpxVV2lD3tsVV1UVb9TVZdW1YVV9eCZaf1EVX2wj/eZqto2895CC4FfrqpPJ3nzTL9NM8v9gl6PTy5Mu6qu1NfPp/qyfW5VHb5oug+rqk/3ej1xd9vF3mqtfTfJvyS5RpJbLHr7X7Lr9vfQJM+deX3LPo0XtNYub619vbX2+tbaOStRNwA4kAkdAFjPHprkef3vPlV13XkDVdWPJ/mNJMdnagFw7KJBnpnk8CQ3TXL3Pt3ZWxLulOSCJNdN8kezI7bWfqx33q5fnX5Rf329Ps0bJPnlJH9dVZtnRn1Akt9NckSmK97vSfIf/fW/JfmzXvdbJXl0kmNaa9dMcp8kF86Zx+9Lcpc+7lxVdY8kf9zLvn6STyV54aLB7pPkDknunOQJSU5N8pAkN0pymyQPmhn2er2+N8j0pfvUXt8k+Wqm5XitJD+R5FFVdf9FZd09ya17mbP1vEaSv0xy3z7PP5rkrP72w/vfcZnW16FJ/mrRdO+a5FZJ7pnk96vq1kstk71V07MmfjHJtzMtt1n/muTEqjqkqn6w1+l9M+9/LMnlVfWcqrrvou0AADY0oQMA61JV3TXJjZO8uLV2ZpL/zNSsfZ4HJPnn1tp5rbWvJdk2M51DkpyY5Ldba19prV2Y5OlJfmFm/Etaa89srX2ntfb1vazit5M8qbX27dba6Ukuy/RFeMHLeyuEbyR5eZJvtNae259p8KIkCy0dLk9y1SQ/WFVXbq1d2Fr7zznlbc50XP/sbur04CTPaq39R2vtm0l+O8ld+m0qC57aWvtya+28JOcmeX1r7YLW2peSvGamXgt+r7X2zdba25K8OtOyTmvtra21D7XWvtuv6L8gU8gwa1tr7atLLNPvJrlNVV29tfbZXp+FefizXqfL+jycuOgWjVN6a4Kzk5yd5Ha7WSZ7cueq+mKSbyT50yQPaa19ftEwFyX5aKZQ66GZWj58T2vty5mCkJbkH5J8obcymQ3J7lzTczgW/uatYwBYd4QOAKxXD8v0hfjS/vr5WfoWiyOTfGbm9Wz3EUmunF2vXn8q09X7ecPvrf9urX1n5vXXMl0BX/BfM91fn/P60CRprX0iya9nCko+X1UvrPkPGNyR6Yv69XdTpyMzM5/9S/t/Z9d53at6LZTZWvvqzOtP9TJSVXeqqrf0W1a+lOSRmZb1rLnLtU/zgX2cz1bVq6vqB+bNQ+/elKkVyoLPzXQvXu7p9Vv4tYzLquqyefXo3ttau1amUOe0TM8Qmee5mVpgPCiLQoc+Tx9prT28tXbDTC1GjkzyjMXlzPzdbDd1AoB1Q+gAwLpTVVfPdEX97lX1uar6XJLHJrldVc27qv3ZJDeceX2jme5LM7VKuPFMv6OSXDzzuq1IxfdTa+35rbWFlh0tyZ/MGeZrmW7R+LndTOqSzMxnv43h2tl1XvfF5j6NBUf1MpIpBDotyY1aa4cn+bsktbjaS024tfa61tq9MoUo52dqIXCFeehlfie7hiN7NPNrGYf2B0XuafjLMj2U8xdmn7cx46WZbiO5oLX26T1M6/xMzyG5ze6GA4CNQOgAwHp0/0y3Hfxgktv3v1sneUem5u2LvTjJL1bVrfuzD35v4Y1+O8OLk/xRVV2zqm6c6fkP/7oP9fmvTM8XWHFVdauqukdNPwn6jUytDb67xOBPSPLwqnp8VV27j3+7qlp4bsMLMi2H2/fpPTnJ+/otJfvrlKq6SlXdLclPJnlJ73/NJNtba9+oqjtm6VtfrqCqrltV9+uBxjcz3ZqyMM8vSPLYqrpJVR3a5+FFi1qVDNFa257kH5P8/pz3vprkHkkesfi9qvqBmh4qesP++kaZWkS8d2yNAWDtCR0AWI8elukZDZ9urX1u4S/TAwUfvOj+/rTWXpPpwYRvSfKJ7Pyyt/CThY/J9ODDC5K8M9NV+mftQ322JXlOvxf/AXsaeB9dNclTMrXI+FyS62R6jsEVtNbenemL7z2SXFBV2zM9CPL0/v4bMwUuL83U+uNmmZ5nsb8+l+m2jksyPczzkf0qfpL8WpInVdVXMn1Jf/E+TPdKmYKfS5Jsz/QsiEf1956V6faFt2f6WcpvZFp/q+UZSU6oqtsufqO1dsYSz9v4SqaHkb6vqr6aafs7N8njZoa5y+ztHv3vmBEzAACrqVpb0xajALDq+q8ZnJvkqqtxhXwjqqpjk/xrf0YBAMBcWjoAcFCoqp+pqqv2nyv8kySvFDgAAIwldADgYPGrST6f6ac1L8/O5voAAAzi9goAAABgCC0dAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGCITWtdgd054ogj2tFHH73W1QAAAABmnHnmmZe21r5/T8Md0KHD0UcfnTPOOGOtqwEAAADMqKpP7c1wbq8AAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQ2xa6wqsd1W16mW21la9TAAAANhXQodl2t8AoKqEBwAAAGxoQgcOalqqAAAAjCN04KCmpQoAAMA4HiQJAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhti01hU4UGzZsiU7duxY1TKratXK2rx5c7Zv375q5a026w8AAODAI3ToduzYkdbaWldjmNX8grwWrD8AAIADj9srAAAAgCGWFTpU1baquriqzup/Jywx3IVV9aE+zBnLKRMAAABYH1bi9oo/b6396V4Md1xr7dIVKA8AAABYB9xeAQAAAAyxEi0dHl1VD01yRpLHtdbm/YRAS/L6qmpJ/r61dupSE6uqk5KclCRHHXXUClRv77STD0u2Hb5q5a22dvJha10FAAAADjK1pyf+V9Ubk1xvzltPTPLeJJdmChX+IMn1W2u/NGcaN2itXVxV10nyhiSPaa29fU+V27p1azvjjNV5BERVbfhfPzB/69dGnz8AAGB9qaozW2tb9zTcHls6tNaO38sC/yHJq5aYxsX9/+er6uVJ7phkj6ED7C0tVQAAAA48y7q9oqqu31r7bH/5M0nOnTPMNZJcqbX2ld597yRPWk65sFid8uUN3RKgqtK2rXUtAAAA9s1yn+nw1Kq6fabbKy5M8qtJUlVHJvnH1toJSa6b5OVVtVDe81trr11muQAAAMABblmhQ2vtF5bof0mSE3r3BUlut5xyAAAAgPXHT2YCAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhti01hUAAACAA1VVrXqZrbVVL3MUoQMAAAAsYX8DgKraUOHB/hI6AADAOuBqK7AeCR0AAGAdcLUVWI88SBIAAAAYQugAAAAADOH2CgAAWEVbtmzJjh07VrXM1XwexObNm7N9+/ZVKw84sAkdAABgFe3YsWNDP2NhLR54uR54ECgHK7dXAAAA7KUtW7akqvb5by3sax23bNmyJvVkY9PSAQAAYC9t5JYqWqkwgpYOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAzh1ysAAADY8LZs2ZIdO3asapmr+Ysgmzdvzvbt21etvL0ldAAAAGDD28g/d5ocuD956vYKAAAAYAihAwAAADCE0AEAAAAYQugAAAAADOFBkmwYB+qDU1bC5s2b17oKAAAA+0zowIaw2k+hraoN/eRbAACAleD2CgAAAGAILR1maJ4PAAAAK0fo0GmeDwAAACvL7RUAAADAEFo6LNNybsnY33G1kFg51h8AAPuinXxYsu3wta7GEO3kw9a6CmxAQodl8gVyfbP+AADYF3XKlzfsOWRVpW1b61qMs5EDo+TADY2EDgAAAGx4GzkwSg7c0MgzHQAAAIAhtHQAAIBVpIk3cDAROgAAwCrSxBs4mLi9AgAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGGLZoUNVPaaqzq+q86rqqUsM8+NV9dGq+kRV/dZyywQAAAAOfJuWM3JVHZfkfklu11r7ZlVdZ84whyT56yT3SnJRkg9U1WmttQ8vp2wAAADgwLbclg6PSvKU1to3k6S19vk5w9wxySdaaxe01r6V5IWZggoAAABgA1tu6HDLJHerqvdV1duq6pg5w9wgyWdmXl/U+81VVSdV1RlVdcYXvvCFZVYPAAAAWCt7vL2iqt6Y5Hpz3npiH39LkjsnOSbJi6vqpq21tr8Vaq2dmuTUJNm6det+TwcAAABYW3sMHVprxy/1XlU9KsnLesjw/qr6bpIjksw2Ubg4yY1mXt+w9wMAAAA2sOXeXvGKJMclSVXdMslVkly6aJgPJLlFVd2kqq6S5MQkpy2zXAAAAOAAt9zQ4VlJblpV52Z6QOTDWmutqo6sqtOTpLX2nSSPTvK6JB9J8uLW2nnLLBcAAAA4wC3rJzP7r1E8ZE7/S5KcMPP69CSnL6csAAAAYH1ZbksHAAAAgLmEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEJvWugIAAADrSVWtdRWG2Lx581pXgQ1I6AAAALCXWmurWl5VrXqZsJLcXgEAAAAMIXQAAAAAhnB7BQAArLKN+kyAxHMBgF0JHQAAYBV5JgBwMHF7BQAAADCElg4AAACDLeeWmv0dVwuXK3Jr0+oTOgAAAAwmAFh7bm1aG26vAAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGGLTWlcAAADYs6pa9XFba/tdJmwUPnvLI3QAAIB1YCN9CYH1xGdvedxeAQAAAAwhdAAAAACGcHsFAMBBYjn3Je8vzZIBDm5CBwCAg8T+BgBVJTwAYL+4vQIAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGGLTWlcAAFhfqmrVy2ytrXqZAMDyCR0AgH2yvwFAVQkPAOAg4/YKAAAAYAgtHQAA1pktW7Zkx44dq1rmat5Ws3nz5mzfvn3VygNgHKEDAMA6s2PHjg19q8paPDcEgDGEDgBwkHK1HAAYTegAAAcpV8sBgNE8SBIAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDeJAkAMA6004+LNl2+FpXY5h28mFrXQUAVojQAQBgnalTvrzhf3mkbVvrWgCwEtxeAQAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGWHTpU1WOq6vyqOq+qnrrEMBdW1Yeq6qyqOmO5ZQIAAAAHvmX9ekVVHZfkfklu11r7ZlVdZzeDH9dau3Q55QEAAADrx3J/MvNRSZ7SWvtmkrTWPr/8KgEAsCdVtdZVGGbz5s1rXQUAVshyQ4dbJrlbVf1Rkm8k+c3W2gfmDNeSvL6qWpK/b62dutQEq+qkJCclyVFHHbXM6gEAbDyttVUtr6pWvUwANoY9hg5V9cYk15vz1hP7+FuS3DnJMUleXFU3bVc8Kt21tXZxv/3iDVV1fmvt7fPK64HEqUmydetWRzcAAABYp/YYOrTWjl/qvap6VJKX9ZDh/VX13SRHJPnComlc3P9/vqpenuSOSeaGDgAAAMDGsNxfr3hFkuOSpKpumeQqSXZ5WGRVXaOqrrnQneTeSc5dZrkAAADAAW65ocOzkty0qs5N8sIkD2uttao6sqpO78NcN8k7q+rsJO9P8urW2muXWS4AAABwgFvWgyRba99K8pA5/S9JckLvviDJ7ZZTDgAAALD+LLelAwAAAMBcQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhljWT2YCAOtXO/mwZNvha12NYdrJh611FQDgoCd0AICDVJ3y5bTW1roaw1RV2ra1rsWBpapWfdyNvI0BsGdCBwCAg4QAAIDV5pkOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBCb1roCAMDaqaq1rsIwmzdvXusqAMBBT+gAAAep1tqqlldVq14mALC23F4BAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYIhlhQ5V9aKqOqv/XVhVZy0x3I9X1Uer6hNV9VvLKRMAAABYHzYtZ+TW2gMXuqvq6Um+tHiYqjokyV8nuVeSi5J8oKpOa619eDllAwAAAAe2Fbm9oqoqyQOSvGDO23dM8onW2gWttW8leWGS+61EuQAAAMCBa1ktHWbcLcl/tdY+Pue9GyT5zMzri5LcaYXKBQ5iU965ulprq14mAACsV3sMHarqjUmuN+etJ7bW/r13PyjzWznss6o6KclJSXLUUUetxCSBDWp/A4CqEh4AAMAq2GPo0Fo7fnfvV9WmJD+b5A5LDHJxkhvNvL5h77dUeacmOTVJtm7d6lsBAAAArFMr8UyH45Oc31q7aIn3P5DkFlV1k6q6SpITk5y2AuUCAAAAB7CVCB1OzKJbK6rqyKo6PUlaa99J8ugkr0vykSQvbq2dtwLlAgAAAAewZT9IsrX28Dn9Lklywszr05OcvtyygI1py5Yt2bFjx6qWuVoPody8eXO2b9++KmUBAMCBZqV+vQJgv+3YsWPDPthxLX5hAwAADhQrcXsFAAAAwBUIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGCITWtdAYB28mHJtsPXuhpDtJMPW+sqAADAmhE6AGuuTvlyWmtrXY0hqipt21rXAgAA1obbKwAAAIAhhA4AAADAEG6vAAD2SVWt+rgb9RYsANjohA4AwD4RAAAAe8vtFQAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQm9a6AgBJUlVrXYUhNm/evNZVAACANSN0ANZca22/xluLoGJ/6woAAAcjoQOwbgkAAADgwOaZDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYYtNyRq6qFyW5VX95rSRfbK3dfs5wFyb5SpLLk3yntbZ1OeUCAAAAB75lhQ6ttQcudFfV05N8aTeDH9dau3Q55QEAAADrx7JChwVVVUkekOQeKzE9AAAAYP1bqWc63C3Jf7XWPr7E+y3J66vqzKo6aXcTqqqTquqMqjrjC1/4wgpVDwAAAFhte2zpUFVvTHK9OW89sbX27737QUlesJvJ3LW1dnFVXSfJG6rq/Nba2+cN2Fo7NcmpSbJ169a2p/oBAAAAB6Y9hg6tteN3935VbUrys0nusJtpXNz/f76qXp7kjknmhg4AAADAxrASt1ccn+T81tpF896sqmtU1TUXupPcO8m5K1AuAAAAcABbidDhxCy6taKqjqyq0/vL6yZ5Z1WdneT9SV7dWnvtCpQLAAAAHMCW/esVrbWHz+l3SZITevcFSW633HIAAACA9WWlfr0CAAAAYBdCBwAAAGAIoQMAAAAwxLKf6QAA+6qqVr3M1tqqlwkAcLATOgCw6vY3AKgq4QEAwDri9goAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYYtNaVwCA9WvLli3ZsWPHqpZZVatW1ubNm7N9+/ZVKw8AYKMROgCw33bs2JHW2lpXY5jVDDgAADYit1cAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABjCT2YCsN/ayYcl2w5f62oM004+bK2rAACwrgkdANhvdcqX01pb62oMU1Vp29a6FgAA65fbKwAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDLDt0qKrbV9V7q+qsqjqjqu64xHAPq6qP97+HLbdcAAAA4MC2aQWm8dQkp7TWXlNVJ/TXx84OUFVbkpycZGuSluTMqjqttbZjBcoHAAAADkArcXtFS3JY7z48ySVzhrlPkje01rb3oOENSX58BcoGAAAADlAr0dLh15O8rqr+NFOI8aNzhrlBks/MvL6o97uCqjopyUlJctRRR61A9QAAAIC1sFehQ1W9Mcn15rz1xCT3TPLY1tpLq+oBSf4pyfH7W6HW2qlJTk2SrVu3tv2dDgAAALC29ip0aK0tGSJU1XOT/N/+8iVJ/nHOYBdn1+c83DDJW/eqhgAAAMC6tBLPdLgkyd179z2SfHzOMK9Lcu+q2lxVm5Pcu/cDAAAANqiVeKbDryT5i6ralOQb6c9jqKqtSR7ZWntEa217Vf1Bkg/0cZ7UWtu+AmUDAAAAB6hq7cB9bMLWrVvbGWecsdbVAGAJVZUD+TiyXBt9/gAA9ldVndla27qn4Vbi9goAAACAKxA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIYQOAAAAwBBCBwAAAGAIoQMAAAAwhNABAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQwgdAAAAgCE2rXUFAFjfqmqtqzDM5s2b17oKAADrmtABgP37/DvhAAAZ30lEQVTWWlvV8qpq1csEAGD/ub0CAAAAGELoAAAAAAwhdAAAAACGEDoAAAAAQ3iQJACrbjm/eLG/43oAJQDA6hM6ALDqBAAAAAcHt1cAAAAAQwgdAAAAgCGEDgAAAMAQQgcAAABgCKEDAAAAMITQAQAAABhC6AAAAAAMIXQAAAAAhhA6AAAAAEMIHQAAAIAhhA4AAADAEEIHAAAAYAihAwAAADCE0AEAAAAYQugAAAAADCF0AAAAAIYQOgAAAABDCB0AAACAIaq1ttZ1WFJVfSHJp9a6HoMckeTSta4E+836W9+sv/XLulvfrL/1y7pb36y/9c36W782+rq7cWvt+/c00AEdOmxkVXVGa23rWteD/WP9rW/W3/pl3a1v1t/6Zd2tb9bf+mb9rV/W3cTtFQAAAMAQQgcAAABgCKHD2jl1rSvAslh/65v1t35Zd+ub9bd+WXfrm/W3vll/65d1F890AAAAAAbR0gEAAAAYQugAAAAADLHhQoequmxOv0dW1UNXoewLq+pDVXVOVb2tqm48usx9UVX/WFU/uNb1WA1VdXlVnTXz91u9/1urap9/tqaq7j+77KrqSVV1/G6GP7aqWlX91Ey/V1XVsXso5+FVdeS+1o+dquqJVXVe/xyeVVUnV9UfLxrm9lX1kd59QH9u98XMdn9eVZ1dVY+rqv3az+/FNr5f+9Wqus/M5/Kyqvpo737u/tRzzvQvmlmfb6mqG63EdNfC7PGsqk6oqo9V1Y2raltVfa2qrjNv2N1M7/SqutYehpm7j+z7pr/a13nYizo9u6o+2beBs6vqnitdxoGmH09aVf3AEu8/u6p+fg/TmF1u51fVyQPqOHvMO+jW0+7M7GvPrqr/qKofHVDG1qr6y2WMv2HX2czyP7eqXrmn/do+TPfoqjp3haY1u/zPqqr/sxLTXaKsY2e3wX6MuLiX++GqetCoskdZ6jx+N8P/zn6U8fI+7U9U1Zdmylrxz3Mv7+ZV9fVexkf6NrJpRFkHog0XOszTWvu71tqKnNDOU5OFZXlca+22Sd6a5HdXaPorskG21h7RWvvwSkxrHfh6a+32M39PWeb07p/keydgrbXfb629cQ/jXJTkiftYzsOTCB32U1XdJclPJvmR/jk8Pslbkjxw0aAnJnnBzOsV/9yukYXt/oeS3CvJfZPs15eRPW3j+7tfba29buFzmeSMJA/ur3cJMJa537tbX5/vTrLPJyLzrOaJweKy+peFv0xy39bap3rvS5M8bl+m21o7obX2xZWp5d5bdIyc5/F9e/j1JH+3QmWu2fraCw9K8s7+fzkWltvtkzysqm6yzOnN2uWYt6i8g2U97c7CvvZ2SX47yR/vaYR91Vo7o7W23C+qG3WdLSz/2yTZnuT/W6067aPHz5yH7nWAVFWH7GM5xyZZ/EX5z/u6v1+Sv6+qK+/jNOfVazW/IO/refzcY/3ujj+ttZ/py+gRSd4xU9a7F01jJef7o73MH05ykyQ/txITXa11sxfH8yUdFKFDT/x+s3e/tar+pKre368a3a33P6SqnlZVH6jpCtmv9v6HVtWbepL9oaq6X+9/dE1X6J6b5Nwki6+mvSfJDWbq8JBe5llV9fcLO5Sq+uVej/dX1T9Uv5LU06+/q6r3JXlqVV2jqp7Vh/vgTD1+aGa651TVLfqwr+7J9rlV9cCZed/aux/U5+fcqvqTmXpeVlV/1Md9b1Vdd8AqOSBU1d9W1Rk1XRU+Zab/U3oyfE5V/WlPPH86ydP6cr5ZzVyJqqpjqurdfZm9v6qu2Sd1dpIvVdW95pR9h5quqp9ZVa+rquv36W1N8rxeztXHL4UN5/pJLm2tfTNJWmuXttbenmRHVd1pZrgHZNfQYcEun9v1rLX2+SQnJXl0P0jM3cclSVX9v74/OLuqntL7zW7ju3wmer/Z/ert+/7inJquHGzu/efub5dSVY+oqldU1VuSvK73+60+/jlV9fszwz5sZt/3NzX/ILh4Pzx3nKr61V6/99XUIuwZvf+/9v3E+5M8uabjwbNn9sM/1Yf74b5cF/bDN62qa1bVa2b2wwvL8t59uA/VtM+/Su9/UV/OH0zyMzN1/rEk/5DkJ1tr/zkzb89K8sCq2jJnOS51vLmwqo7o3b9X0zHsnVX1goV12f2vJdbZjfo6/XjNXFmvqt/o83huVf1673eFY2Rfduf2eX/sXqyvK+wne/9jamdLpqdVvzJZU2uM06rqzUne1Ps9fmabP6X3W+oYOW87P7qq3tz7vamqjur9dzlGz5mXuarq0CR3TfLLmcLPhZO4v+rL641JZluw/H6v/7lVdWpV1ZzJXq3//2of5559+/xQTecNV91D/z0e8w629bSPDkuyo5c395yxvzf3M7eb5XRsVb2qd2/r6+ytVXVBzVw1X2q6i2zkdfa9eVtq+feyPlLTPve8qnp99XOsvizOrqqzMxNeVNXVquqf+3Q+WFXHzSyLV1TVG2rapz66pn3gB2s6Dl5hnzyrdn/+/fRej7vsZh39n5ll+cKqOjrJI5M8tq+3XY6zrbWPJ/lakoXj8s2q6rV9uu+o3uKq939vr9sfVm8917fDd1TVaUk+3Ptd4RjT/66wj19c395vS1+G5/Qyb9v7b6uqf6mqdyW56pxld3jf1m/VX7+gqn6lpvOWq/f6PK/mH3/mnvPvZj3tckyu6fvV6/pye3tV3bIPd92qelmf9vur6s69/z36dnVW3x6vsWi9fCfJB7Jz291UVX9WO893HtH7H9I/D+f37fa1VXX/fazjiX29nF3T+dXc85be/wm183j+mN7v5n0dPi/JeZnOtfdda21D/SW5bE6/bUl+s3e/NcnTe/cJSd7Yu09K8ru9+6qZrsDdJMmmJIf1/kck+USSSnJ0ku8mufNMORcmOaJ3PyPJSb371klemeTK/fXfJHlopivaFybZkuTKSd6R5K/6MM9O8qokh/TXT07ykN59rSQfS3KNJM/MdKUwSa6S5OqZUrN/mKnX4TPzvrWX++kk39/n781J7t+HaUl+qnc/dWGZrLe/JJcnOWvm74Gzy6B3b+n/D+n9b5vk2kk+mnzvl12uNbM+fn5m+s9O8vN9mV+Q5Jje/7C+TI/t6+/Hkrytv/eq3v/Kma7Afn/v/8Akz1pcP3/7td4P7ev7Y/1zdvfe/zczpf5JcuckZ8yMM/dzux7/Mn//98Uk183S+7j79u3x+/p7C5+LhW18qc/Etuzcr54zs6yflOQZvfutmbO/nanbLtt7pqsNn0qyeWacv8m0z71SktdmuppzmySvSLKpD3dqkv/duy+aqeMzk/xS7547TqbA+JOZTsiu0pfFQv3/tY9zpf76qUlO7N2b+3Z2tSR/m537mKv2fg9M8rcz83Z4ku/r9btZ7/e8JI+eqfdvLFo+3850Fe+2i/pvy7RN/36SU2bXfZY43sxu60mOyfQ5uVqSayb5ePZ8jHx4ks9m2h6unulEbmuSOyT5UKbj0aGZTkj+RxYdI/twb5iZhyvsWzNdXX9+797dfvLcJHfp3U9Jcu5MHS/Kzm343n09L2w/C/vkKxwjs/R2/sokD+vdv5TkFTP1/t4xeh8+ow9O8k+9+919ufxskjdkOhYdmekzu7BMtsyM+y/ZeXx+dqbt9qwklyV5cu9/tSSfSXLL/vq5ma5yL9V/n455B8t62ov1uHCOcX6SLyW5Q++/1Dnj7j5zSy2nY5O8auYz/+5M+5cjkvx3X/a7m+6GXWfZub87JMlLkvz4Hpb/0Um+k+T2/b0XZ+c59TlJfqx3P21mnh83s1x+INN589X6svhEX97fn2n9P7IP9+dJfn3OZ/SsTFe293T+/YC9WEeXJLnqomW5bWG9L36d5EcyXcVfeO9NSW7Ru++U5M29+1VJHtS7HzmzjI/NFGjepL9e6jvNUvv4efV9ZpKTe/c9kpw1U+8zMx1jljqPv1emoOnEJK9dvE307qNzxe9oVzjnn3nv2PTP2ky/XY7JmVrNLhy7/2eS1/fuF2Xnce7o7Nx+XpPkTr370F7uzWfm9epJ3pbkh/rrX0vyW737qkk+mOSoPp+vzPQ5OzLT9nb/fazjR5Jcd9E6mHfecqdMF0yvnmn7/kim7fbmfXku6/vJQXMfySIv6//PzLSBJNMO9La18z7Kw5PcItMKfXJNV5u+mymRWrj6/6nW2nsXTfstPeW8LMnv9X73zPRh/EBNFymunuTzSe6Y6Qvp9iSpqpckueXMtF7SWrt8pn4/XTsT7Ktl2hjfk+SJVXXDJC9rrX28qj6U5Ok9QX1Va+0di+p4TJK3tta+0Mt9XqaDxSuSfCvTjmdh+VzhKv068fU2NV/anQdU1UmZdvzXz9SU9MNJvpHkn2q6wvCq3YyfJLdK8tnW2geSpLX25STp6zmttbdXVarqrovGuU2SN/ThDsl0Ms8ytdYuq6o7JLlbkuOSvKim+wBflOTdVfW4XPHWimT+53ajWWofd3ySf26tfS1JFvZHM76U3XwmqurwTAext/Vez8l0Erhg3v52d17fWtsxU+f7Zjr4JtOB+5aZgtdjkpwxs0/9zMw03lFV18705W3hPtDjlxjnW5lOuhauVP5bpn3rgpe01r47W5/aeW/pwn743Ul+t6bngbystfaJqjonyVP6FZhXttbe1bfNj7WdLRaem+mK98KzEl60aFl8u0/7l5P83znL6i+TnFX9ymG31PFm1v9M8u+ttW8k+UZVvXLR+0utsze01v47SarqZZmu2LckL2+tfXWm/92SnJZdj5EXJLlpVT0zyauTvH5muk+rqicnuWGSu/R+c/eTNd27fc3W2nv6cM/PdEvVbB0XtuF797/Z7ecWmQL+XY6RNTVNnbed3yVTKJBMX/pnr7zOHqP31oOS/EXvfmF/vSnJC/q0LqnpavKC46rqCZkCqy2ZQp2F9fX41tq/1dR64k01tVD4apJPttY+1od5Tqart29Zov9fLTHf8xxM62lPvneOUdNtfc+tqttk+oI775xx7mduL5bTrFe3qRXfN6vq87ub7oyNus6uXlVnZVq+H8kU2iVLL/9k2v7P6t1nJjm6z/O12tQicqEe9+3dd8305TittfOr6lPZeY7+ltbaV5J8paq+lJ2fyQ9luoC14PGttX9beFFTy4ulzr8vT/LSPujuzhPPydQi9hV9vKU8tqp+sdd5oVXeoZmC+5fUzkZTCy0K7pIpnEqmdT97XHl/a+2TvXupY8wrM38fP6++d02/raC19uaqunZVHdbfO6219vWqmnse31p7Q1X9ryR/neR2u5n/xd/R5p3zn7Ob8ZN+TO7byZ2TvHRmuS18hz4+ya1m+m+uqRXNu5L8RV/HL+3np+nDnpXkppmCtvP6ePdOcuuqOrG/XjhHu2uSF/fzkEuqauFca1/q+K5M+6iXZOfxfd55y117Xb/ep/mKTMfz1yf5z9baGXtYXrt1sIYO3+z/L8/OZVBJHtNae93sgFX18EyJ5B1aa9+uqguzqCnjIsdlOtF9XpJTkvxGn/ZzWmu/vWja97/i6LuYnX4l+bnW2kcXDfORmpqg/USS06vqV/sH+EcyXaX6w6p6U2vtSXsoa8G3W4+9suvy2VBquvf1NzO1UNhRVc9OcrXW2neq6o6Zdqo/n+TRmVLY5fijTM8J+M5C8UnOa63dZelR2F/9ROWtSd7aA7iHtdaeXVWfTHL3TAe6xct+3ud23evN5S7PdEKw1D7uPrubxgp8Jubtb3dn8X7vD1tr/zQ7QE3NNp/VWlsqILpbn84LMj3T4gl9WlcYp/bwwL459bl/2/U2hyT5WFW9J9N++LVV9Us9cNyaaT/8lKp6TfotI3tZVjKdND8g0xfK32mtPXn2zdbaF6vq+dn1fua5x5t9tNQ6a4uGW/x6se/NT9/P3i7JfTJdRXtApqubyc4vz4/JdNvIHbLEfrL2/MC4xevrj1trf794oHnHyP3YzuedAyypB5v3SPLDVdUyfZFoSV6+xPBXy3QVcWtr7TNV/3975xpjV1XF8d+/DyNNEYzWpBYt4aFBIwEN8FFJNFErVkxjCgVrbYyWpgbiC2ONo8WgQalWY6sQiGkRYgBTSCpTSzA1lVpJ0frAB0o0JCBFUmzCSKtdfvjv03vmzjl37rxSZ7p+X2bm3Dn77LP3WWuvs/Za62qAjv1xnGLM/hQbp6M9Y93njkW+T4p5GisR8bCctrSg9LXNZpwoL9Z+71efztQ5G4qICyTNw8/8WuyEXUH7+HeP30RSWOttHav9fYzx283/rjlaetmJS7Cj4jK86fimlvY2RsTXJL0XO3zOxrvlh/rYlOume+4b15gWHd9vf5uuNQI5LfI8OikjT47WTpvNP0o/6m0Ip+42jZuAiyPiSNfxG+SUlCXAXrk2U1BqOkhaADws6d0RsaO0c01EPNh1v5fTm376+BEcxfAeYL+kCyNia7fd0ud1xs1JUdOhTwaBNSqFViS9Ts6/OQ14piivS4HFozUUztO5FvhgMTIeBJapVBqXc5kW41yet0p6efEE9yomMgisU3FfSbqw/DwL+Gu4QM12vJP5auCFiNiGQ8Xe3NXWvnLdV8q5vlfgEJ+TiZdhAXperlvxLjjuBT6tKIDr6HhRD+NQo27+CCyUdFE5/1R1FXOJiJ1YMZ5fO2eBvDuCpLmS3jjKdZI+kPR6SefWDl2Aw/XBL6AbsbyMWKQa5HZaUxa0LThlK2jXcT8BVhXjje577yETAETE87hmRpVHejWTp08GgdWln0g6oxj3u/CuRVWf4BUq+cC1fh3F8/nhYky3nbMP7yafXsbm/bQzCKyr/qjr4Yh4PCK+iXfxzpe0CId7bgW+jvXwY8C5RW8DXMUoYxWOQFkCrJC0uuFfbgY+SsfQbVtv6uwBLpNzlufTvrPazTtKe6fgHbE9eGfzfZLmlXm6vBwbRhn3WRFxD3bCdq9L4F33WcUR1qgnw4UwD6tTo2V5QzsVg3j+55c2Fkl6VdMa2eM5/3ntGiua7m0MLAO2RsTiiDgzIqrUnn/i+hyz5bztS8v/V0bxs6V/jQ6ysuZcAvwFj9uZks4pH1fy2Hh8HGsezPx5GhNyTvxsPI9tNmOjzI1xnJroV5Zn5JwV/fhx4BNFDsZks5d7PqRONOqK2sc/q/6Wc+Nfi8duIvRrfzfOkfzC/ZqIeAj4DL7f+fSQ14i4D6dTrgxH4z4hRwogU83HXjrvIb3mvnGNadLxPfpbH9u34Zflf/W4Zp3r8Fp6JXC7OgUyj6q9WGajzd8v4UjIp1QcAJJm1cZtF8NrgVQRUGdHxIGIuBHYj6NX6m0exEVoK+fNIHBN9Q5R7NkqYmJZmauF2IEz1j6eVaI+Po/rzyxqslvwvFwu6ZQit0uZRF06E3ex50mqv1Dc3Od5t+Iw0v2SBBzERtUdwP3yjukjOH9vVCLiKUl3AmsjYoOk9cDOIoBHy/G9ctjbPpy3W+UGNrEB55sfKG08gReXDwBXSzoKPI1rP1yEQ+qOlWutaejb9TjcUjhkb3s/9zWNqELvKh6IiONftxMRv5YLr/wBh1jvKR+dCmyXd5hEZ8f7LuAWuXjTslo7R+RCSd8qymEIh1p182XsFKrOWQZskkPT5+C5/R3OAdwiaQjnVQ5NZBBOQubjuTgdR5Y8jmsZgEP+N1F7aeymLrdY5qYb1XM/F9//Vjo6sFHHRcQDZZF8RNIRYAfDq0C3yUSdlfi5nYfD6FdNxs1ExI5i0O91lzmMazf8Ri4EtaumUz+Gc2Xr5z8phxOuiYgbm86JiF9Kugk7gZ/Dxl6bHv4i8I2yHszCz9dS4Er5K8mO4vzVARzC+pWih4+Ua70gOw7uLQbnL3CRyNHG4TlJ7wR2SzrY9dmzkn6EDTEi4vdN6w0d5xvlnu/DoaX/wCHBbfdcZx8O/z0D2BYl1FLeNdpX/ufWiHhULm5WZxE2EKvNjhG7ZBERkm4APh0Rgz305Gqsj49hg72x7xGxU9J5eDcJnD51Fc5P7V4j257zdaXfn8IyM5Fn+wrgq13H7sG7dn/G6X1/x2mTVSTLLTjP/mn8jNa5qcz1S/CLwL1lDFfh8Ok55ZwtEfFi03GcstH3mlf6NdPnqR/qNobwC91/5VDqETbjKDLX1zg10a8sz+Q5K/rmAJav8djsq4Db5OijetrXd4DNpa3/AB8qcjSeblZ97cv+7mEn/gnYVo4J2FT0xP3A3XL6RpON8yXgB0WfrCj3tR7bCnfhPP5rS9ufw/WT2ua+bY0ZYqSOn93S3wE85gdwxMLKhkuNsOOB23Htp4sj4rCk3djB8QVcY+SApP10fXNcD5t/LCzH4zaAde42PG5ry/FVeJ4eKsc+KW/GHMPyuZPhqZsAdwMDcvHJ75bPf1WesWewffFDHBn0GF7HH6VdR7T1caMc7SGcwvpbSeu77ZYyN3fSWWs2F3vrnBFXGgdVUZfkBCFpfjg0cg4OsbwtIhpDLZMkSZLJp6aH52Ln4OaI6M6NnlHU7nkesBsXUN1/ovvVD1Xfy+/XAwsjoqnmRXICyXkaTpvMTXScJlOWc85OXsrzM1QcVMtxUcmlo52XTD01GV+ANysuKZES04qZGOkw3RiQ9HYcRrmT3kVhkiRJkslngxzi+VK8mzJaAdmZwPckvQHf8/eni8OhsETSZ7EN8zdcTT75/yPnaThtMjfRcZpMWc45O3l5C/BteZv9EJ2aO8mJ58dyoc25+Fs/pp3DATLSIUmSJEmSJEmSJEmSKSILSSZJkiRJkiRJkiRJMiWk0yFJkiRJkiRJkiRJkikhnQ5JkiRJkiRJkiRJkkwJ6XRIkiRJkiRJkiRJkmRKSKdDkiRJkiRJkiRJkiRTwv8AIZX72LQRcCoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "fig.suptitle('Algorithms Comparison - RMSE')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig('images/ml_comparison_rmse_h.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_h_tune'></a>\n",
    "\n",
    "## Hyper-parameter Tuning\n",
    "\n",
    "`Hyper-parameters` are parameters that are not directly learnt within estimators. It is possible and recommended to search the hyper-parameter space **for the best cross validation score**.\n",
    "\n",
    "While using a grid of parameter settings is currently the most widely used method for parameter optimization (`GridSearchCV`), other search methods have more favourable properties. `RandomizedSearchCV` implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:\n",
    "\n",
    "- A budget can be chosen independent of the number of parameters and possible values.\n",
    "- Adding parameters that do not influence the performance does not decrease efficiency.\n",
    "\n",
    "Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for `GridSearchCV`. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the n_iter parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified: loguniform(1, 100) can be used instead of [1, 10, 100]. \n",
    "\n",
    "-----\n",
    "\n",
    "## Grid Search: hyper-parameters tuning\n",
    "https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "Some models allow for specialized, efficient parameter search strategies, outlined below. Two generic approaches to sampling search candidates are provided in scikit-learn: for given values, GridSearchCV exhaustively considers all parameter combinations, while RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution.\n",
    "\n",
    "Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.\n",
    "\n",
    "While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favourable properties. RandomizedSearchCV implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:\n",
    "\n",
    "- A budget can be chosen independent of the number of parameters and possible values.\n",
    "\n",
    "- Adding parameters that do not influence the performance does not decrease efficiency.\n",
    "\n",
    "## Cross-validation: evaluating estimator performance\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test.\n",
    "\n",
    "When evaluating different settings (hyperparameters) for estimators, such as the C setting that must be manually set for an SVM, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can leak into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called validation set: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k folds:\n",
    "\n",
    "- A model is trained using  of the folds as training data;\n",
    "\n",
    "- the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n",
    "\n",
    "dac obrazek ze strony, zrobic source: sklearn\n",
    "\n",
    "## Pipelines and composite estimators\n",
    "https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "Transformers are usually combined with classifiers, regressors or other estimators to build a composite estimator. The most common tool is a Pipeline.\n",
    "\n",
    "Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
    "\n",
    "Convenience and encapsulation\n",
    "You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "\n",
    "Joint parameter selection\n",
    "You can grid search over parameters of all estimators in the pipeline at once.\n",
    "\n",
    "Safety\n",
    "Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n",
    "## Model persistence\n",
    "https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "\n",
    "After training a scikit-learn model, it is desirable to have a way to persist the model for future use without having to retrain. The following section gives you an example of how to persist a model with pickle. \n",
    "\n",
    "pickle (and joblib by extension), has some issues regarding maintainability and security. Because of this,\n",
    "\n",
    "- Never unpickle untrusted data as it could lead to malicious code being executed upon loading.\n",
    "\n",
    "- While models saved using one version of scikit-learn might load in other versions, this is entirely unsupported and inadvisable. It should also be kept in mind that operations performed on such data could give different and unexpected results.\n",
    "\n",
    "In order to rebuild a similar model with future versions of scikit-learn, additional metadata should be saved along the pickled model:\n",
    "\n",
    "- The training data, e.g. a reference to an immutable snapshot\n",
    "\n",
    "- The python source code used to generate the model\n",
    "\n",
    "- The versions of scikit-learn and its dependencies\n",
    "\n",
    "- The cross validation score obtained on the training data\n",
    "\n",
    "- This should make it possible to check that the cross-validation score is in the same range as before.\n",
    "\n",
    "Since a model internal representation may be different on two different architectures, dumping a model on one architecture and loading it on another architecture is not supported.\n",
    "\n",
    "more: https://pyvideo.org/pycon-us-2014/pickles-are-for-delis-not-software.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_cv2(X_train, y_train, model, param_grid, scoring, num_folds = 6, seed = 123):\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score'] \n",
    "    stds = grid_result.cv_results_['std_test_score'] \n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "        #print(\"{:0.2f} ({:0.2f}) with: {}\".format(mean, stdev, param))\n",
    "    #print('-------')\n",
    "    print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/hyperparameter-tuning-c5619e7e6624\n",
    "def perform_random_search_cv2(X_train, y_train, model, param_grid, scoring, num_folds = 6, seed = 123):\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    grid = RandomizedSearchCV(estimator=model,\n",
    "                            param_distributions=param_grid,\n",
    "                            scoring=scoring,\n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            n_iter=1000)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score'] \n",
    "    stds = grid_result.cv_results_['std_test_score'] \n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev, param in zip(means, stds, params):\n",
    "        #print(\"{:0.2f} ({:0.2f}) with: {}\".format(mean, stdev, param))\n",
    "    #print('-------')\n",
    "    print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#LinearRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "# Linear regression with combined L1 and L2 priors as regularizer.\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
    "    \"max_iter\": [1, 10, 100, 1000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "model = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.559832349894503 using {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}\n",
      "CPU times: user 8min 30s, sys: 3min 59s, total: 12min 30s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: -5.559832349894503 using {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}\n",
    "CPU times: user 8min 30s, sys: 3min 59s, total: 12min 30s\n",
    "Wall time: 2min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2458 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2984 tasks      | elapsed:   34.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.564184376166167 using {'selection': 'cyclic', 'max_iter': 10, 'l1_ratio': 0.9, 'fit_intercept': True, 'alpha': 0.1}\n",
      "CPU times: user 10.8 s, sys: 1.5 s, total: 12.3 s\n",
      "Wall time: 40.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3985 out of 4000 | elapsed:   40.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:   40.8s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LinearRegression - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
    "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   11.4s\n",
    "[Parallel(n_jobs=-1)]: Done 2458 tasks      | elapsed:   27.9s\n",
    "[Parallel(n_jobs=-1)]: Done 2984 tasks      | elapsed:   34.8s\n",
    "Best: -5.564184376166167 using {'selection': 'cyclic', 'max_iter': 10, 'l1_ratio': 0.9, 'fit_intercept': True, 'alpha': 0.1}\n",
    "CPU times: user 10.8 s, sys: 1.5 s, total: 12.3 s\n",
    "Wall time: 40.9 s\n",
    "[Parallel(n_jobs=-1)]: Done 3985 out of 4000 | elapsed:   40.7s remaining:    0.2s\n",
    "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:   40.8s finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#ElasticNet\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "# Linear regression with combined L1 and L2 priors as regularizer.\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
    "    \"max_iter\": [1, 10, 100, 1000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "model = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.559832349894503 using {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}\n",
      "CPU times: user 8min 53s, sys: 4min 26s, total: 13min 20s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: -5.559832349894503 using {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}\n",
    "CPU times: user 8min 53s, sys: 4min 26s, total: 13min 20s\n",
    "Wall time: 2min 33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1146 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1632 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 tasks      | elapsed:   48.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.5639353632257675 using {'selection': 'random', 'max_iter': 100, 'l1_ratio': 0.7000000000000001, 'fit_intercept': True, 'alpha': 0.1}\n",
      "CPU times: user 14.9 s, sys: 1.61 s, total: 16.5 s\n",
      "Wall time: 56.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:   56.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ElasticNet - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
    "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed:    7.2s\n",
    "[Parallel(n_jobs=-1)]: Done 1146 tasks      | elapsed:   22.4s\n",
    "[Parallel(n_jobs=-1)]: Done 1632 tasks      | elapsed:   34.2s\n",
    "[Parallel(n_jobs=-1)]: Done 3000 tasks      | elapsed:   48.2s\n",
    "Best: -5.5639353632257675 using {'selection': 'random', 'max_iter': 100, 'l1_ratio': 0.7000000000000001, 'fit_intercept': True, 'alpha': 0.1}\n",
    "CPU times: user 14.9 s, sys: 1.61 s, total: 16.5 s\n",
    "Wall time: 56.4 s\n",
    "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:   56.4s finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluded\n",
    "%%time\n",
    "#DecisionTreeRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "# Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "param_grid = {\n",
    "    \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"max_depth\": range(2, 16, 2),\n",
    "    \"min_samples_split\": range(2, 16, 2),\n",
    "    \"min_samples_leaf\": range(2, 16, 2),\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": [0.001, 0.01, 0.1, 0, 1, 10, 100, 1000]\n",
    "}\n",
    "model = models[3][1]\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.563871725667823 using {'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'bootstrap': True, 'n_estimators': 500, 'n_jobs': -1}\n",
      "CPU times: user 1min 10s, sys: 1.73 s, total: 1min 11s\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BaggingRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "# https://www.programcreek.com/python/example/85938/sklearn.ensemble.BaggingRegressor\n",
    "# A Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "# The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree.\n",
    "param_grid = {\n",
    "    \"base_estimator\": [models[0][1]],\n",
    "    \"n_estimators\": [100, 200, 500, 1000, 5000, 10000],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "model = models[6][1]\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: -5.563871725667823 using {'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'bootstrap': True, 'n_estimators': 500, 'n_jobs': -1}\n",
    "CPU times: user 1min 10s, sys: 1.73 s, total: 1min 11s\n",
    "Wall time: 6min 13s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.566746325950773 using {'n_jobs': -1, 'n_estimators': 200, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "CPU times: user 443 ms, sys: 46.1 ms, total: 489 ms\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BaggingRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.1min finished\n",
    "Best: -5.566746325950773 using {'n_jobs': -1, 'n_estimators': 200, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
    "CPU times: user 443 ms, sys: 46.1 ms, total: 489 ms\n",
    "Wall time: 4min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 0 ns, total: 6 s\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#RandomForestRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "# https://www.programcreek.com/python/example/85938/sklearn.ensemble.BaggingRegressor\n",
    "# A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],#, 1000, 5000, 10000],\n",
    "    #\"criterion\": [\"mse\", \"mae\"],\n",
    "    #\"bootstrap\": [True, False],\n",
    "    \"ccp_alpha\": [0.001, 0.01, 0.1, 0, 1, 10],#, 100, 1000],\n",
    "    \"max_depth\": [10, 20, 30, 40, None],#50, 60, 70, 80, 90, 100, None],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    #\"min_samples_split\": range(2, 16, 2),\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "model = models[7][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 109.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 139.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 175.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 229.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4050 out of 4050 | elapsed: 229.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.611958006937581 using {'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'ccp_alpha': 0}\n",
      "CPU times: user 1min 3s, sys: 4.94 s, total: 1min 8s\n",
      "Wall time: 3h 49min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#RandomForestRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
    "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.2min\n",
    "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 30.5min\n",
    "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 46.8min\n",
    "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 78.1min\n",
    "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 109.5min\n",
    "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 139.0min\n",
    "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 175.4min\n",
    "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 229.0min\n",
    "[Parallel(n_jobs=-1)]: Done 4050 out of 4050 | elapsed: 229.4min finished\n",
    "Best: -5.611958006937581 using {'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'ccp_alpha': 0}\n",
    "CPU times: user 1min 3s, sys: 4.94 s, total: 1min 8s\n",
    "Wall time: 3h 49min 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 0 ns, total: 6 s\n",
      "Wall time: 9.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ExtraTreesRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\n",
    "# https://www.programcreek.com/python/example/102434/sklearn.ensemble.ExtraTreesRegressor\n",
    "# This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 500],#, 1000, 5000, 10000],\n",
    "    #\"criterion\": [\"mse\", \"mae\"],\n",
    "    #\"bootstrap\": [True, False],\n",
    "    \"ccp_alpha\": [0.001, 0.01, 0.1, 0, 1, 10],#, 100, 1000],\n",
    "    \"max_depth\": [10, 20, 30, 40, None],#50, 60, 70, 80, 90, 100, None],\n",
    "    #\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    #\"min_samples_split\": range(2, 16, 2),\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "model = models[8][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 93.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed: 107.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -5.550630838028553 using {'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_depth': 20, 'ccp_alpha': 0}\n",
      "CPU times: user 23.8 s, sys: 2.48 s, total: 26.3 s\n",
      "Wall time: 1h 47min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ExtraTreesRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.4s\n",
    "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 11.3min\n",
    "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 33.8min\n",
    "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 58.9min\n",
    "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 93.3min\n",
    "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed: 107.5min finished\n",
    "Best: -5.550630838028553 using {'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_depth': 20, 'ccp_alpha': 0}\n",
    "CPU times: user 23.8 s, sys: 2.48 s, total: 26.3 s\n",
    "Wall time: 1h 47min 34s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best models on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True,\n",
      "                 fit_intercept={'alpha': 0.1, 'fit_intercept': True,\n",
      "                                'l1_ratio': 0.9, 'max_iter': 10,\n",
      "                                'selection': 'cyclic'},\n",
      "                 n_jobs=None, normalize=False))\n",
      "('ElasticNet', ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.9,\n",
      "           max_iter=10, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=LinearRegression(copy_X=True,\n",
      "                                                 fit_intercept=True,\n",
      "                                                 n_jobs=None, normalize=False),\n",
      "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                 max_samples=1.0, n_estimators=500, n_jobs=-1, oob_score=False,\n",
      "                 random_state=None, verbose=0, warm_start=False))\n",
      "('RandomForestRegressor', RandomForestRegressor(bootstrap=True, ccp_alpha=0, criterion='mse',\n",
      "                      max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=500, n_jobs=-1, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False))\n",
      "('ExtraTreesRegressor', ExtraTreesRegressor(bootstrap=False, ccp_alpha=0, criterion='mse', max_depth=20,\n",
      "                    max_features='auto', max_leaf_nodes=None, max_samples=None,\n",
      "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                    min_samples_leaf=4, min_samples_split=2,\n",
      "                    min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "                    oob_score=False, random_state=None, verbose=0,\n",
      "                    warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "best_models = [\n",
    "    LinearRegression({'selection': 'cyclic', 'max_iter': 10, 'l1_ratio': 0.9, 'fit_intercept': True, 'alpha': 0.1}),\n",
    "    ElasticNet(**{'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.9, 'max_iter': 10, 'selection': 'cyclic'}),\n",
    "    BaggingRegressor(**{'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'bootstrap': True, 'n_estimators': 500, 'n_jobs': -1}),\n",
    "    RandomForestRegressor(**{'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'ccp_alpha': 0}),\n",
    "    ExtraTreesRegressor(**{'n_jobs': -1, 'n_estimators': 500, 'min_samples_leaf': 4, 'max_depth': 20, 'ccp_alpha': 0})\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for model in best_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 6.828320349509234, (std. dev. 1.1765435471515016)\n",
      "ElasticNet, RMSE 6.362445093286155, (std. dev. 1.3735950444778768)\n",
      "BaggingRegressor, RMSE 6.741902866871671, (std. dev. 1.2375756214055105)\n",
      "RandomForestRegressor, RMSE 7.470411301420557, (std. dev. 3.266147545644302)\n",
      "ExtraTreesRegressor, RMSE 7.629586333849936, (std. dev. 3.1862423905356776)\n"
     ]
    }
   ],
   "source": [
    "scores, results, names = score_ml_models(X_train=X_test,\n",
    "                                         y_train=y_test,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\", \n",
    "                                         seed=123)\n",
    "\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='data_d'></a>\n",
    "\n",
    "## Load daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "common.py | 42 | get_pm25_data_for_modelling | 04-Jun-20 23:06:19 | INFO: Dataframe loaded: /Users/ksatola/Documents/git/air-polution/agh/data/dfpm25_2008-2018_ml_7days_lags.hdf\n",
      "common.py | 43 | get_pm25_data_for_modelling | 04-Jun-20 23:06:19 | INFO: Dataframe size: (4014, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-5</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>-16.374909</td>\n",
       "      <td>-47.645172</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.625808</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>-16.374909</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.621035</td>\n",
       "      <td>13.625808</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>5.134971</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.678291</td>\n",
       "      <td>-21.621035</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>17.628909</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.641890</td>\n",
       "      <td>8.678291</td>\n",
       "      <td>13.625808</td>\n",
       "      <td>4.290823</td>\n",
       "      <td>7.381350</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t        t-1        t-3        t-4        t-5  month  day  hour  \\\n",
       "0   4.290823   7.381350   5.134971 -16.374909 -47.645172      1    6     0   \n",
       "1  13.625808   4.290823  17.628909   5.134971 -16.374909      1    7     0   \n",
       "2 -21.621035  13.625808   7.381350  17.628909   5.134971      1    8     0   \n",
       "3   8.678291 -21.621035   4.290823   7.381350  17.628909      1    9     0   \n",
       "4  11.641890   8.678291  13.625808   4.290823   7.381350      1   10     0   \n",
       "\n",
       "   dayofyear  weekofyear  dayofweek  quarter  season  \n",
       "0          6           1          6        1       1  \n",
       "1          7           2          0        1       1  \n",
       "2          8           2          1        1       1  \n",
       "3          9           2          2        1       1  \n",
       "4         10           2          3        1       1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd = get_pm25_data_for_modelling('ml', 'd')\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_d'></a>\n",
    "\n",
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_df_for_ml_modelling(data=dfd, \n",
    "                                                             target_col='t', \n",
    "                                                             train_size=0.02) # train_size=0.00024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3933, 12)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 12)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))\n",
      "('ElasticNet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False))\n",
      "('SVR', SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))\n",
      "('DecisionTreeRegressor', DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best'))\n",
      "('KNeighborsRegressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform'))\n",
      "('AdaBoostRegressor', AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                 n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                 warm_start=False))\n",
      "('RandomForestRegressor', RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False))\n",
      "('ExtraTreesRegressor', ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
      "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                    max_samples=None, min_impurity_decrease=0.0,\n",
      "                    min_impurity_split=None, min_samples_leaf=1,\n",
      "                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                    n_estimators=10, n_jobs=None, oob_score=False,\n",
      "                    random_state=None, verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "# Define regression models in scope\n",
    "reg_models = get_models_for_regression()\n",
    "models = []\n",
    "\n",
    "for model in reg_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 13.143886676634612, (std. dev. 0.42758394413212353)\n",
      "ElasticNet, RMSE 13.131853794028634, (std. dev. 0.43576815454789974)\n",
      "SVR, RMSE 13.823720574691311, (std. dev. 0.2945517705423598)\n",
      "DecisionTreeRegressor, RMSE 19.18873823140993, (std. dev. 0.8872352989071995)\n",
      "KNeighborsRegressor, RMSE 14.588892279746142, (std. dev. 0.4463272629786315)\n",
      "AdaBoostRegressor, RMSE 13.854147945337223, (std. dev. 0.33244863460665397)\n",
      "BaggingRegressor, RMSE 14.350252355219094, (std. dev. 0.29953723885220973)\n",
      "RandomForestRegressor, RMSE 14.455900445749682, (std. dev. 0.24241607280346159)\n",
      "ExtraTreesRegressor, RMSE 14.509192727169573, (std. dev. 0.32735725010262295)\n",
      "CPU times: user 5.84 s, sys: 274 ms, total: 6.11 s\n",
      "Wall time: 5.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Perform initial ranking\n",
    "scores, results, names = score_ml_models(X_train=X_train,\n",
    "                                         y_train=y_train,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\", \n",
    "                                         seed=123)\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "fig.suptitle('Algorithms Comparison - RMSE')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig('images/ml_comparison_rmse_d.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='model_d_tune'></a>\n",
    "\n",
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 8 s, total: 24 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LinearRegression\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
    "    \"max_iter\": [1, 10, 100, 1000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "model = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.126226564857761 using {'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.7000000000000001, 'max_iter': 10, 'selection': 'random'}\n",
      "CPU times: user 2min 20s, sys: 19.7 s, total: 2min 40s\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: -13.126226564857761 using {'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.7000000000000001, 'max_iter': 10, 'selection': 'random'}\n",
    "CPU times: user 2min 20s, sys: 19.7 s, total: 2min 40s\n",
    "Wall time: 41.4 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 2 s, total: 20 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ElasticNet\n",
    "param_grid = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"l1_ratio\": np.arange(0.0, 1.0, 0.1),\n",
    "    \"max_iter\": [1, 10, 100, 1000],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "model = models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.12422705933348 using {'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.6000000000000001, 'max_iter': 10, 'selection': 'random'}\n",
      "CPU times: user 2min 31s, sys: 22.5 s, total: 2min 53s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: -13.12422705933348 using {'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.6000000000000001, 'max_iter': 10, 'selection': 'random'}\n",
    "CPU times: user 2min 31s, sys: 22.5 s, total: 2min 53s\n",
    "Wall time: 46.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 224 s, total: 241 s\n",
      "Wall time: 507 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SVR\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "# Epsilon-Support Vector Regression. \n",
    "# The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.\n",
    "# The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function ignores samples whose prediction is close to their target.\n",
    "param_grid = {\n",
    "    \"kernel\": [\"linear\", \"rbf\"],#, \"poly\", \"sigmoid\"], \n",
    "    \"degree\": [3],#[1, 2, 3, 4],\n",
    "    \"C\": [1.5, 10],\n",
    "    #\"gamma\": [\"scale\", \"auto\"],\n",
    "    'epsilon':[0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "}\n",
    "model = models[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 24.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.141117773500117 using {'kernel': 'linear', 'epsilon': 0.5, 'degree': 3, 'C': 10}\n",
      "CPU times: user 3min 28s, sys: 1.08 s, total: 3min 29s\n",
      "Wall time: 27min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SVR  - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.5min\n",
    "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 24.2min finished\n",
    "Best: -13.141117773500117 using {'kernel': 'linear', 'epsilon': 0.5, 'degree': 3, 'C': 10}\n",
    "CPU times: user 3min 28s, sys: 1.08 s, total: 3min 29s\n",
    "Wall time: 27min 44s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 45 s, total: 56 s\n",
      "Wall time: 103 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoostRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor\n",
    "# An AdaBoost [1] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional \n",
    "# copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. \n",
    "# As such, subsequent regressors focus more on difficult cases.\n",
    "# The base estimator from which the boosted ensemble is built. If None, then the base estimator is DecisionTreeRegressor(max_depth=3).\n",
    "param_grid = {\n",
    "    \"base_estimator\": [models[0][1]],\n",
    "    \"n_estimators\": [100, 200, 500],#, 1000, 5000, 10000],\n",
    "    \"loss\": [\"linear\", \"square\", \"exponential\"]\n",
    "}\n",
    "model = models[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.376934994077676 using {'n_estimators': 200, 'loss': 'linear', 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "CPU times: user 328 ms, sys: 114 ms, total: 442 ms\n",
      "Wall time: 2.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#AdaBoostRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "Best: -13.376934994077676 using {'n_estimators': 200, 'loss': 'linear', 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
    "CPU times: user 328 ms, sys: 114 ms, total: 442 ms\n",
    "Wall time: 2.15 s\n",
    "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    2.1s finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 s, sys: 7 s, total: 14 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BaggingRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "# https://www.programcreek.com/python/example/85938/sklearn.ensemble.BaggingRegressor\n",
    "# A Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "# The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree.\n",
    "param_grid = {\n",
    "    \"base_estimator\": [models[0][1]],\n",
    "    \"n_estimators\": [100, 200, 500, 1000, 5000, 10000],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "model = models[6][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "perform_grid_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -13.141310202266377 using {'n_jobs': -1, 'n_estimators': 100, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
      "CPU times: user 313 ms, sys: 30.2 ms, total: 343 ms\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BaggingRegressor - Random Search\n",
    "perform_random_search_cv2(X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        model=model, \n",
    "                        param_grid=param_grid, \n",
    "                        scoring='neg_root_mean_squared_error', \n",
    "                        num_folds=6, \n",
    "                        seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.4s\n",
    "Best: -13.141310202266377 using {'n_jobs': -1, 'n_estimators': 100, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}\n",
    "CPU times: user 313 ms, sys: 30.2 ms, total: 343 ms\n",
    "Wall time: 1min 45s\n",
    "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best models on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LinearRegression', LinearRegression(copy_X=True,\n",
      "                 fit_intercept={'alpha': 1, 'fit_intercept': False,\n",
      "                                'l1_ratio': 0.7000000000000001, 'max_iter': 10,\n",
      "                                'selection': 'random'},\n",
      "                 n_jobs=None, normalize=False))\n",
      "('ElasticNet', ElasticNet(alpha=1, copy_X=True, fit_intercept=False,\n",
      "           l1_ratio=0.6000000000000001, max_iter=10, normalize=False,\n",
      "           positive=False, precompute=False, random_state=None,\n",
      "           selection='random', tol=0.0001, warm_start=False))\n",
      "('SVR', SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.5, gamma='scale',\n",
      "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False))\n",
      "('AdaBoostRegressor', AdaBoostRegressor(base_estimator=LinearRegression(copy_X=True,\n",
      "                                                  fit_intercept=True,\n",
      "                                                  n_jobs=None,\n",
      "                                                  normalize=False),\n",
      "                  learning_rate=1.0, loss='linear', n_estimators=200,\n",
      "                  random_state=None))\n",
      "('BaggingRegressor', BaggingRegressor(base_estimator=LinearRegression(copy_X=True,\n",
      "                                                 fit_intercept=True,\n",
      "                                                 n_jobs=None, normalize=False),\n",
      "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                 max_samples=1.0, n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                 random_state=None, verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "best_models = [\n",
    "    LinearRegression({'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.7000000000000001, 'max_iter': 10, 'selection': 'random'}),\n",
    "    ElasticNet(**{'alpha': 1, 'fit_intercept': False, 'l1_ratio': 0.6000000000000001, 'max_iter': 10, 'selection': 'random'}),\n",
    "    SVR(**{'kernel': 'linear', 'epsilon': 0.5, 'degree': 3, 'C': 10}),\n",
    "    AdaBoostRegressor(**{'n_estimators': 200, 'loss': 'linear', 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}),\n",
    "    BaggingRegressor(**{'n_jobs': -1, 'n_estimators': 100, 'bootstrap': True, 'base_estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)})\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for model in best_models:\n",
    "    item = (type(model).__name__, model)\n",
    "    models.append(item)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression, RMSE 13.048955489499978, (std. dev. 1.579505939681471)\n",
      "ElasticNet, RMSE 11.967137144731709, (std. dev. 1.209049991528524)\n",
      "SVR, RMSE 11.798205904606231, (std. dev. 1.5691210883592683)\n",
      "AdaBoostRegressor, RMSE 14.214767389976393, (std. dev. 1.5669097096940707)\n",
      "BaggingRegressor, RMSE 12.913849222119717, (std. dev. 1.5620223443945112)\n"
     ]
    }
   ],
   "source": [
    "scores, results, names = score_ml_models(X_train=X_test,\n",
    "                                         y_train=y_test,\n",
    "                                         models=models,\n",
    "                                         n_splits = 5,\n",
    "                                         metric='neg_root_mean_squared_error',\n",
    "                                         metric_label=\"RMSE\", \n",
    "                                         seed=123)\n",
    "\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression, RMSE 13.048955489499978, (std. dev. 1.579505939681471)\n",
    "ElasticNet, RMSE 11.967137144731709, (std. dev. 1.209049991528524)\n",
    "SVR, RMSE 11.798205904606231, (std. dev. 1.5691210883592683)\n",
    "AdaBoostRegressor, RMSE 14.214767389976393, (std. dev. 1.5669097096940707)\n",
    "BaggingRegressor, RMSE 12.913849222119717, (std. dev. 1.5620223443945112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, 'model.joblib') \n",
    "model2 = load('model.joblib')\n",
    "model2.predict(X[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
